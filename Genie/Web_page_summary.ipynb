{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### âš¡ _A note before you begin_\n",
    "\n",
    "Please follow the article to have LLM locally insatalled in your machine to carry on with this exercise:  \n",
    "[Hello World of Agentic AI](https://www.linkedin.com/pulse/hello-world-agentic-ai-vishal-jindal-q4csc/?trackingId=aaxwcpx%2BSXqX0quowmnFmw%3D%3D)\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message  `Ollama is running`\n",
    "\n",
    "If not, bring up a new Terminal/PowerShell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal/PowerShell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "Don't forget to activate your python virtual environment/set as Kernel for Jupyter Notebook and install dependencies via requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of prompts**\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "Models like GPT4o have been trained to receive instructions in a particular way.\n",
    "They expect to receive:\n",
    "\n",
    " - **A system prompt** that tells them what task they are performing and\n",
    "   what tone they should use \n",
    " - **A user prompt** -- the conversation starter    that they should reply\n",
    "   to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi, kindly help me writing a leave application to my manager\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help you write a leave application to your manager. Here's a sample template you can use as a guide:\n",
      "\n",
      "**Formal Leave Application Template**\n",
      "\n",
      "[Your Name]\n",
      "[Your Designation]\n",
      "[Company Name]\n",
      "[Date]\n",
      "\n",
      "Manager's Name\n",
      "[Department]\n",
      "\n",
      "Dear [Manager's Name],\n",
      "\n",
      "I am writing to request [number of days] days of leave from [start date] to [end date]. I have made sure to check the company calendar and have not taken any leaves in the last [X] months.\n",
      "\n",
      "I will be out of the office during this period due to [personal reasons/medical emergency/holiday/vacation etc.]. I will ensure that all my tasks are completed before my leave and make arrangements for their completion while I am away.\n",
      "\n",
      "I would greatly appreciate it if you could approve my leave request. If there are any issues or concerns, please let me know as soon as possible so that I can address them.\n",
      "\n",
      "Thank you for your understanding and support.\n",
      "\n",
      "Sincerely,\n",
      "[Your Signature]\n",
      "[Your Name]\n",
      "\n",
      "**Note:**\n",
      "\n",
      "- You can customize the template to fit your specific needs.\n",
      "- Make sure to check with your company's leave policy before submitting your application.\n",
      "- If you have any outstanding tasks or projects, be sure to mention them in the application so that your manager is aware of the situation.\n",
      "- Keep a professional tone and avoid using overly casual language.\n",
      "\n",
      "Before submitting your application, please review it carefully to ensure it accurately reflects your needs and circumstances.\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages_for(website),\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "    return response.json()['message']['content']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the rewritten text in a more organized and concise format:\n",
       "\n",
       "**Artificial Intelligence (AI)**\n",
       "\n",
       "AI encompasses models, algorithms, and techniques used to simulate human intelligence. It can be categorized into several subfields, including machine learning, natural language processing, computer vision, and robotics.\n",
       "\n",
       "* **Machine Learning**: AI systems learn from data and improve their performance over time.\n",
       "* **Natural Language Processing**: AI understands, generates, and processes human language.\n",
       "* **Computer Vision**: AI interprets and makes decisions based on visual information from images and videos.\n",
       "* **Robotics**: AI enables robots to perform tasks that typically require human intelligence.\n",
       "\n",
       "**Generative AI**\n",
       "\n",
       "Generative AI models create new data that resembles the training data. These models can generate images, text, music, and more, often producing results indistinguishable from real-world examples.\n",
       "\n",
       "* **Generative Adversarial Networks (GANs)**: GANs consist of two neural networks that are trained simultaneously through adversarial processes.\n",
       "* **Variational Autoencoders (VAEs)**: VAEs are a type of autoencoder that generates data by encoding inputs into a latent space and then decoding from this space to generate outputs.\n",
       "* **Transformer-based Models**: Transformer models, such as GPT, learn to predict the next item in a sequence, making them capable of generating coherent and contextually relevant text, images, music, and more.\n",
       "\n",
       "**Deep Learning**\n",
       "\n",
       "Deep learning is a subfield of machine learning that involves the use of neural networks with multiple layers. These models can be used for image recognition, natural language processing, speech recognition, and more.\n",
       "\n",
       "* **Convolutional Neural Networks (CNNs)**: CNNs are designed to process pixel data and are used extensively in image recognition, object detection, and video analysis.\n",
       "* **Recurrent Neural Networks (RNNs)**: RNNs are designed for processing sequential data and are used for tasks such as language translation, speech recognition, and text generation.\n",
       "\n",
       "**Applications of AI**\n",
       "\n",
       "AI has numerous applications across various industries, including:\n",
       "\n",
       "* **Healthcare**: AI is used in medical imaging, disease diagnosis, personalized medicine, and healthcare management.\n",
       "* **Finance**: AI is used in risk assessment, portfolio optimization, sentiment analysis, and customer service.\n",
       "* **Retail**: AI is used in recommendation systems, inventory management, supply chain optimization, and customer service.\n",
       "\n",
       "Overall, AI has the potential to transform industries and improve lives by automating tasks, making decisions, and generating insights from large amounts of data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://medium.com/@jereljohnvelarde/whats-the-relationship-of-ai-ml-dl-and-generative-ai-1f4c8295432a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
